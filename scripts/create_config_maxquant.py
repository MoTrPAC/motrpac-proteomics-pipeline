import argparse
import getopt
import os
import re
import sys
import warnings
import json
from google.cloud import storage
from pathlib import Path

warnings.filterwarnings("ignore", "Your application has authenticated using end user credentials")

def arg_parser():
    parser = argparse.ArgumentParser(description='Script to generate a proteomics configuration file from raw files in buckets')
    parser.add_argument('-g', '--gcp_project', required=True, type=str, help='GCP project name')
    parser.add_argument('-b', '--bucket_name_config', required=True, type=str, help='Bucket name with config files')
    parser.add_argument('-p', '--parameters_maxquant', required=True, type=str, help='MaxQuant parameter FILE location on GCP (relative to bucket_name_config)')
    # parser.add_argument('-s', '--study_design_location', required=True, type=str, help='Proteomics study design location on GCP (relative to bucket_name_config)')
    parser.add_argument('-q', '--sequence_db', required=True, type=str, help='Sequence db file location (relative to bucket_name_config, including folder)')
    parser.add_argument('-v', '--bucket_name_raw', required=True, type=str, help='Bucket name with raw files')
    parser.add_argument('-f', '--folder_raw', required=True, type=str, help='Full path to the proteomics raw files on GCP, without including bucket name')
    parser.add_argument('-d', '--docker_respository', required=True, type=str, help='Docker repository for MaxQuant')
    parser.add_argument('-o', '--output_folder_local', required=True, type=str,help='Path to which JSON outputs should be written')
    parser.add_argument('-y', '--output_config_yaml', required=True, type=str, help='File name for the JSON file generated by this script')
    parser.add_argument('-e', '--experiment_prot', required=True, type=str, help='Proteomics experiment. One of the following: pr, ph, ub, ac')
    return parser

def main():
    # PROCESS ARGUMENTS
    parser = arg_parser()
    args = parser.parse_args()

    gcp_project = args.gcp_project
    bucket_name_config = args.bucket_name_config.rstrip('/')

    parameters_maxquant = args.parameters_maxquant.rstrip('/')
    parameters_maxquant_full = 'gs://' + bucket_name_config + '/' + parameters_maxquant

    # study_design_location = args.study_design_location.rstrip('/')
    # full_study_design = 'gs://' + bucket_name_config + '/' + study_design_location

    sequence_db = args.sequence_db.rstrip('/')
    sequence_db_full = 'gs://' + bucket_name_config + '/' + sequence_db

    bucket_name_raw = args.bucket_name_raw.rstrip('/')
    folder_raw = args.folder_raw.rstrip('/')
    full_folder_raw = 'gs://' + bucket_name_raw + '/' + folder_raw

    docker_respository = args.docker_respository.rstrip('/')

    output_folder_local = args.output_folder_local.rstrip('/')
    output_config_yaml = args.output_config_yaml

    experiment_prot = args.experiment_prot

    # Summary to the user
    print("\nWRITE JSON CONFIG FILE FOR MAXQUANT PROTEOMICS PIPELINE")
    print("----------------------------------------------")
    print("+ GCP gcp_project:", gcp_project)
    print("+ Raw file location: ", full_folder_raw)
    # print("+ Study design location: ", full_study_design)
    print("+ MaxQuant parameters FILE location: ", parameters_maxquant_full)
    print("+ Docker repository: ", docker_respository)

    # Provide relative to the script
    dirname = os.path.dirname(__file__)

    # Validate proteomics experiment
    print("+ Proteomics experiment: ", experiment_prot)
    
    # Load maxquant template file
    template = os.path.join(os.getcwd(), dirname,
                            '../inputs/templates/config-maxquant.json'
                            )
    
    # READ TEMPLATE CONFIG FILE
    print('+ Template json: ', template)

    with open(template) as json_file:
        text = json_file.read()
        json_data = json.loads(text)
        # print(json_data)
        # print(json.dumps(json_data, indent=4, sort_keys=True))

    # Load and process raw files' blobs
    storage_client = storage.Client(gcp_project)
    all_blobs = storage_client.list_blobs(bucket_name_raw, prefix=folder_raw)

    print("+ Load raw files from GCP")

    i = 0
    raw_files = []

    for blob in all_blobs:
        if blob.name.endswith('.raw'):
            filename = blob.name
            # print('\t- Raw file location: ', filename)
            a = 'gs://' + bucket_name_raw + '/' + filename
            raw_files.append(a)
            i += 1

    # CHECK POINT IF RAW FILES ARE NOT FOUND
    if i == 0:
        print("\n\tERROR: No raw files found in location <",bucket_name_config,">")
        exit()
    else:
        print("+ Total number of raw files found: ", i)

    # Assign number of CPUs
    ncpu = 0
    mq_ram_gb = 0

    if i >= 95:
        ncpu = 95
        mq_ram_gb = 95*4
    else:
        ncpu = i
        mq_ram_gb = i*4

    # WRITE JSON FILE

    # DOCKER CPUS and RAM
    json_data['proteomics_maxquant.mq_ncpu'] = ncpu
    json_data['proteomics_maxquant.mq_ramGB'] = mq_ram_gb

    # RAW-FILES
    json_data['proteomics_maxquant.raw_file'] = raw_files

    # SEQUENCE DB
    json_data['proteomics_maxquant.fasta_sequence_db'] = sequence_db_full

    json_data['proteomics_maxquant.mq_parameters'] = parameters_maxquant_full

    # STUDY DESIGN
    # json_data['proteomics_maxquant.sd_fractions'] = full_study_design + '/fractions.txt'
    # json_data['proteomics_maxquant.sd_references'] = full_study_design +  '/references.txt'
    # json_data['proteomics_maxquant.sd_samples'] = full_study_design + '/samples.txt'

    for (k, v) in json_data.items():
        if 'docker-repository' in str(v):
            # print("\tKey: " + k + ", Value: " + str(v))
            json_data[k] = json_data[k].replace('docker-repository', docker_respository)

    # print("\nCHECK new PARAMETER VALUE")
    # for (k, v) in json_data.items():
    #     if 'parameters' in str(v):
    #         print("Key: " + k + ", Value: " + str(v))

    # print("\nCHECK NEW DOCKER REGISTRY VALUE:")
    # for (k, v) in json_data.items():
    #     if 'gcr' in str(v):
    #         print("Key: " + k + ", Value: " + str(v))

    full_path_filename = os.path.join(output_folder_local, output_config_yaml)
    print('+ Full path for the config-yaml file: ', full_path_filename)

    Path(output_folder_local).mkdir(parents=True, exist_ok=True)

    with open(full_path_filename, 'w') as outfile:
        json.dump(json_data, outfile, indent=4)

    print('+ ALL DONE!')

if __name__ == "__main__":
    main()

