import argparse
import json
import os
import sys
import warnings
from pathlib import Path

from google.cloud import storage


warnings.filterwarnings(
    "ignore", "Your application has authenticated using end user credentials"
)


def arg_parser():
    parser = argparse.ArgumentParser(
        description='Script to generate a proteomics configuration file from raw files '
                    'in buckets'
    )
    parser.add_argument(
        '-g', '--gcp_project', required=True, type=str, help='GCP project name'
    )
    parser.add_argument(
        '-b', '--bucket_name_config', required=True, type=str,
        help='Bucket name with config files'
    )
    parser.add_argument(
        '-p', '--parameters_maxquant', required=True, type=str,
        help='MaxQuant parameter FILE location on GCP (relative to bucket_name_config)'
    )
    parser.add_argument(
        '-q', '--sequence_db', required=True, type=str,
        help='Sequence db file location (relative to bucket_name_config, including '
             'folder)'
    )
    parser.add_argument(
        '-v', '--bucket_name_raw', required=True, type=str,
        help='Bucket name with raw files'
    )
    parser.add_argument(
        '-f', '--folder_raw', required=True, type=str,
        help='Full path to the proteomics raw files on GCP, without including bucket name'
    )
    parser.add_argument(
        '-d', '--docker_respository', required=True, type=str,
        help='Docker repository for MaxQuant'
    )
    parser.add_argument(
        '-o', '--output_folder_local', required=True, type=str,
        help='Path to which JSON outputs should be written'
    )
    parser.add_argument(
        '-y', '--output_config_yaml', required=True, type=str,
        help='File name for the JSON file generated by this script'
    )
    parser.add_argument(
        '-e', '--experiment_prot', required=True, type=str,
        help='Proteomics experiment. One of the following: pr, ph, ub, ac'
    )
    return parser


def main():
    # PROCESS ARGUMENTS
    parser = arg_parser()
    args = parser.parse_args()

    gcp_project = args.gcp_project
    bucket_name_config = args.bucket_name_config.rstrip('/')

    parameters_maxquant = args.parameters_maxquant.rstrip('/')
    parameters_maxquant_full = 'gs://' + bucket_name_config + '/' + parameters_maxquant

    sequence_db = args.sequence_db.rstrip('/')
    sequence_db_full = 'gs://' + bucket_name_config + '/' + sequence_db

    bucket_name_raw = args.bucket_name_raw.rstrip('/')
    folder_raw = args.folder_raw.rstrip('/')
    full_folder_raw = 'gs://' + bucket_name_raw + '/' + folder_raw

    docker_repository = args.docker_respository.rstrip('/')

    output_folder_local = args.output_folder_local.rstrip('/')
    output_config_yaml = args.output_config_yaml

    experiment_prot = args.experiment_prot

    # Summary to the user
    print("\nWRITE JSON CONFIG FILE FOR MAXQUANT PROTEOMICS PIPELINE")
    print("----------------------------------------------")
    print("+ GCP gcp_project:", gcp_project)
    print("+ Raw file location: ", full_folder_raw)
    # print("+ Study design location: ", full_study_design)
    print("+ MaxQuant parameters FILE location: ", parameters_maxquant_full)
    print("+ Docker repository: ", docker_repository)

    # Provide relative to the script
    dirname = os.path.dirname(__file__)

    # Validate proteomics experiment
    print("+ Proteomics experiment: ", experiment_prot)

    # Load maxquant template file
    template = os.path.join(
        os.getcwd(), dirname,
        '../inputs/templates/config-maxquant.json'
    )

    # READ TEMPLATE CONFIG FILE
    print('+ Template json: ', template)

    with open(template, encoding="utf-8") as json_file:
        text = json_file.read()
        json_data = json.loads(text)
        # print(json_data)
        # print(json.dumps(json_data, indent=4, sort_keys=True))

    # Load and process raw files' blobs
    storage_client = storage.Client(gcp_project)
    all_blobs = storage_client.list_blobs(bucket_name_raw, prefix=folder_raw)

    print("+ Load raw files from GCP")

    i = 0
    raw_files = []

    for blob in all_blobs:
        if blob.name.endswith('.raw'):
            filename = blob.name
            # print('\t- Raw file location: ', filename)
            a = 'gs://' + bucket_name_raw + '/' + filename
            raw_files.append(a)
            i += 1

    # CHECK POINT IF RAW FILES ARE NOT FOUND
    if i == 0:
        print("\n\tERROR: No raw files found in location <", bucket_name_config, ">")
        sys.exit()
    else:
        print("+ Total number of raw files found: ", i)

    # Assign number of CPUs
    ncpu = 0
    mq_ram_gb = 0

    if i >= 95:
        ncpu = 95
        mq_ram_gb = 95 * 4
    else:
        ncpu = i
        mq_ram_gb = i * 4

    # WRITE JSON FILE

    # DOCKER CPUS and RAM
    json_data['proteomics_maxquant.mq_ncpu'] = ncpu
    json_data['proteomics_maxquant.mq_ramGB'] = mq_ram_gb

    # RAW-FILES
    json_data['proteomics_maxquant.raw_file'] = raw_files

    # SEQUENCE DB
    json_data['proteomics_maxquant.fasta_sequence_db'] = sequence_db_full

    json_data['proteomics_maxquant.mq_parameters'] = parameters_maxquant_full

    for (k, v) in json_data.items():
        if 'docker-repository' in str(v):
            # print("\tKey: " + k + ", Value: " + str(v))
            json_data[k] = json_data[k].replace('docker-repository', docker_repository)

    full_path_filename = os.path.join(output_folder_local, output_config_yaml)
    print('+ Full path for the config-yaml file: ', full_path_filename)

    Path(output_folder_local).mkdir(parents=True, exist_ok=True)

    with open(full_path_filename, 'w', encoding="utf-8") as outfile:
        json.dump(json_data, outfile, indent=4)

    print('+ ALL DONE!')


if __name__ == "__main__":
    main()
