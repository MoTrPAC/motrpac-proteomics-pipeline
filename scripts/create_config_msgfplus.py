import argparse
import json
import os
import warnings
from pathlib import Path

from google.cloud import storage


warnings.filterwarnings(
    "ignore", "Your application has authenticated using end user credentials"
)


def proteomics_experiments():
    """
    List of supported proteomic experiments

    :return: list of prot experiments
    """
    prot_exp = [
        "pr-tmt11",
        "pr-tmt16",
        "ph-tmt11",
        "ph-tmt16" "ub-tmt11",
        "ub-tmt16",
        "ac-tmt11",
        "ac-tmt16",
        "pr-lf",
        "ph-lf",
        "ub-lf",
        "ac-lf",
    ]

    return prot_exp


def create_arguments():
    """
    Creates argument parser instance with all the valid commands for the OmicsPipelines CLI

    :return: ArgumentParser object with valid options
    :rtype: argparse.ArgumentParser
    """
    parser = argparse.ArgumentParser(
        description="Script to generate a proteomics configuration file "
        "from raw files in buckets"
    )
    parser.add_argument(
        "-g", "--gcp_project", required=True, type=str, help="GCP project name"
    )
    parser.add_argument(
        "-o",
        "--output_folder_local",
        required=True,
        type=str,
        help="Path to which JSON outputs should be written on your local computer",
    )
    parser.add_argument(
        "-y",
        "--output_config_json",
        required=True,
        type=str,
        help="File name for the JSON configuration file generated by this script",
    )
    parser.add_argument(
        "-m",
        "--quant_method",
        required=True,
        type=str,
        help="Quantification method: [label-free or tmt]",
    )
    parser.add_argument(
        "-e",
        "--experiment_prot",
        required=True,
        type=str,
        help="Proteomics experiment. "
        f'One of the following: {" ".join(str(x) for x in proteomics_experiments())}',
    )
    parser.add_argument(
        "-b",
        "--bucket_name_config",
        required=True,
        type=str,
        help="Bucket name with configuration files",
    )
    parser.add_argument(
        "-p",
        "--parameters_msgf",
        required=True,
        type=str,
        help="MS-GF+ parameter FOLDER (with parameter files) location "
        "on GCP (must be relative to <bucket_name_config>)",
    )
    parser.add_argument(
        "-s",
        "--study_design_location",
        required=True,
        type=str,
        help="Proteomics study design location on GCP (relative to <bucket_name_config>)",
    )
    parser.add_argument(
        "-q",
        "--sequence_db",
        required=True,
        type=str,
        help="Sequence db file location (relative to bucket_name_config, including "
        "folder)",
    )
    parser.add_argument(
        "-v",
        "--bucket_name_raw",
        required=False,
        type=str,
        help="Optional: Bucket name with raw files. Required only if it is different "
        "from <bucket_name_config>",
    )
    parser.add_argument(
        "-f",
        "--folder_raw",
        required=True,
        type=str,
        help="Full path to the proteomics raw files on GCP, without including bucket "
        "name relative to bucket_name_raw (if it is different from "
        "bucket_name_config)",
    )
    parser.add_argument(
        "-d",
        "--docker_msgf",
        required=True,
        type=str,
        help="Docker repository for MSGF+ applications",
    )
    parser.add_argument(
        "-r",
        "--results_prefix",
        required=False,
        type=str,
        help="Results files name prefix (which will end in _ratio.txt and "
        "_RII-peptides.txt",
    )
    parser.add_argument(
        "-x",
        "--pr_ratio",
        required=False,
        type=str,
        help="Optional: Global proteomics <ratio.txt> results file "
        "(for inferred PTM searches)",
    ),
    parser.add_argument(
        "-c",
        "--species",
        required=True,
        type=str,
        help="Species: scientific name for the specie to which the samples belong",
    ),
    parser.add_argument(
        "-u",
        "--unique_only",
        action="store_true",
        help="The presence of this flag determines whether to discard peptides that "
        "match multiple proteins in the parsimonious protein inference step. "
        "It would ignore arguments -g and -r. Default: FALSE",
    ),
    parser.add_argument(
        "-i",
        "--refine_prior",
        action="store_true",
        help="The presence of this flag determines whether peptides are allowed to "
        "match multiple proteins in the prior. That is, the greedy set cover "
        "algorithm is only applied to the set of proteins not in the prior. If "
        "FALSE (default), the algorithm is applied to the prior and non-prior sets "
        "separately before combining",
    ),
    parser.add_argument(
        "-a",
        "--sequence_db_name",
        required=True,
        type=str,
        help="Name of Protein database (either RefSeq or UniProt)",
    ),

    return parser


class MSGFConfigurationGenerator:
    """
    This class contains the configuration options and post-processing methods
    """

    bucket_name_config: str
    parameters_msgf: str
    gcp_project: str
    quant_method: str
    study_design_location: str
    experiment_prot: str
    bucket_full_path: str
    results_prefix: str
    species: str
    sequence_db: str
    pr_ratio: str
    bucket_name_raw: str
    folder_raw: str
    docker_msgf: str
    refine_prior: bool
    unique_only: bool
    sequence_db_name: str
    output_folder_local: str
    output_config_json: str

    def __init__(self):
        """
        Creates a new MSGFConfigurationGenerator class

        Sets the parser and raw args as individual attributes of the class, then
        iterates over all passed in args and sets them as attributes of the class
        """
        parser = create_arguments()
        self._parser = parser
        self.args = parser.parse_args()
        for key, val in self.args.__dict__.items():
            setattr(self, key, val)
        self.template = None
        self.json_data = None

    def sanitize_options(self):
        """
        Strips any slashes, adds any necessary prefixes, and sets them back to the
        attributes of the class
        """

        self.bucket_name_config = self.args.bucket_name_config.rstrip("/")

        parameters_msgf = self.args.parameters_msgf.rstrip("/")
        self.parameters_msgf = f"gs://{self.bucket_name_config}/{parameters_msgf}"

        study_design_location = self.args.study_design_location.rstrip("/")
        self.study_design_location = (
            f"gs://{self.bucket_name_raw}/{study_design_location}"
        )

        sequence_db = self.args.sequence_db.rstrip("/")
        self.sequence_db = f"gs://{self.bucket_name_config}/{sequence_db}"

        if self.bucket_name_raw is not None:
            self.bucket_name_raw = self.args.bucket_name_raw.rstrip("/")
        else:
            self.bucket_name_raw = self.bucket_name_config

        folder_raw = self.args.folder_raw.rstrip("/")
        self.folder_raw = f"gs://{self.bucket_name_raw}/{folder_raw}"

        self.docker_msgf = self.args.docker_msgf.rstrip("/")

        self.output_folder_local = self.args.output_folder_local.rstrip("/")
        self.output_config_json = self.args.output_config_json

    def argument_validation_output(self):
        """
        Prints a summary of the passed-in args to the user
        """

        print("\nWRITE JSON CONFIG FILE FOR PROTEOMICS PIPELINE")
        print("----------------------------------------------")
        print("+ GCP gcp_project:", self.gcp_project)
        print("+ Quantification method:", self.quant_method)
        print("+ Raw file location: ", self.folder_raw)
        print("+ Study design location: ", self.study_design_location)
        print("+ MSGFplus parameter FOLDER location: ", self.parameters_msgf)
        print("+ Docker registry for MSGF containers: ", self.docker_msgf)
        print("+ Species: ", self.species)
        if self.pr_ratio is not None:
            print(
                "+ Global proteomics file (for prioritized inference): ", self.pr_ratio
            )

    def load_template(self):
        """
        Loads the JSON template of the selected assay, raises a ValueError if the assay
        that the user passed in is not a valid option/does not have a template JSON

        :return: The loaded JSON template as a dict
        :rtype: dict
        :raise: ValueError
        """

        # Relative path to script from directory
        dirname = Path(os.path.abspath(os.path.dirname(__file__))).parent
        # print(f'{dirname=}')

        print("+ Proteomics experiment: ", self.experiment_prot)
        self.template = os.path.join(
            dirname,
            f"inputs/templates/msgfplus/config-msgfplus-{self.experiment_prot}.json",
        )
        print("+ Template json path: ", self.template)

        try:
            # READ TEMPLATE CONFIG FILE
            with open(self.template) as json_file:
                text = json_file.read()
                json_data = json.loads(text)
        except FileNotFoundError:
            raise ValueError(
                f"The value {self.experiment_prot} passed in for the <experiment_prot> "
                f"argument is not supported. Only one of the following are expected: "
                f'{" ".join(str(x) for x in proteomics_experiments())}'
            ) from FileNotFoundError

        self.json_data = json_data

    def save_configuration(self, json_data):
        """
        Saves the configured json template to the user-passed in output directory

        :param json_data: The edited template JSON dict
        """
        # save files out to output directories
        output_path = os.path.join(self.output_folder_local, self.output_config_json)
        print("+ Full path for the config-yaml file: ", output_path)

        Path(self.output_folder_local).mkdir(parents=True, exist_ok=True)

        with open(output_path, "w") as outfile:
            json.dump(json_data, outfile, indent=4)

    def load_and_process_raw_files(self):
        """
        Searches for the raw files that the pipeline will process and returns a string
        of the addresses in GCS

        :return: A list of strings with the raw files formatted
        :rtype: list[str]
        """
        # Load and process raw files' blobs
        storage_client = storage.Client(self.gcp_project)
        all_blobs = storage_client.list_blobs(
            self.bucket_name_raw, prefix=self.args.folder_raw
        )

        print("+ Loading raw files from GCP")
        raw_files = []

        for (i, blob) in enumerate(all_blobs):
            if blob.name.endswith(".raw"):
                filename = blob.name
                a = "gs://" + self.bucket_name_raw + "/" + filename
                raw_files.append(a)

        # CHECK POINT IF RAW FILES ARE NOT FOUND
        if len(raw_files) == 0:
            raise FileNotFoundError(
                f"ERROR: No raw files found in location {self.bucket_full_path}"
            )
        else:
            print("+ Total number of raw files found: ", len(raw_files))

        return raw_files

    def fill_json(self):
        if self.results_prefix is not None:
            self.json_data["proteomics_msgfplus.results_prefix"] = self.results_prefix
        else:
            self.json_data[
                "proteomics_msgfplus.results_prefix"
            ] = "omicspipelines-prot-results"

        raw_files = self.load_and_process_raw_files()

        # WRITE JSON FILE
        # RAW-FILES
        self.json_data["proteomics_msgfplus.raw_file"] = raw_files
        # SEQUENCE DB
        self.json_data["proteomics_msgfplus.fasta_sequence_db"] = self.sequence_db
        # STUDY DESIGN
        if self.study_design_location is not None:
            self.json_data["proteomics_msgfplus.sd_fractions"] = (
                self.study_design_location + "/fractions.txt"
            )
            self.json_data["proteomics_msgfplus.sd_references"] = (
                self.study_design_location + "/references.txt"
            )
            self.json_data["proteomics_msgfplus.sd_samples"] = (
                self.study_design_location + "/samples.txt"
            )
        # GCP-PARAMETERS
        for (k, v) in self.json_data.items():
            if "gcp-parameters" in str(v):
                # print("\tKey: " + k + ", Value: " + str(v))
                self.json_data[k] = self.json_data[k].replace(
                    "gcp-parameters", self.parameters_msgf
                )
            elif "docker-repository" in str(v):
                # print("\tKey: " + k + ", Value: " + str(v))
                self.json_data[k] = self.json_data[k].replace(
                    "docker-repository", self.docker_msgf
                )
        # RESULTS FILE NAME:
        if self.results_prefix is not None:
            self.json_data["proteomics_msgfplus.results_prefix"] = self.results_prefix
        else:
            self.json_data[
                "proteomics_msgfplus.results_prefix"
            ] = "omicspipelines-prot-results"

        # PTM ONLY: Prioritized inference
        if self.pr_ratio is not None:
            self.json_data["proteomics_msgfplus.pr_ratio"] = self.pr_ratio
        else:
            if "pr_ratio" in self.json_data:
                del self.json_data["proteomics_msgfplus.pr_ratio"]

        # QUANTIFICATION METHODS: check supported options
        supported_quant_methods = ["label-free", "tmt"]
        if self.quant_method in supported_quant_methods:
            self.json_data["proteomics_msgfplus.quant_method"] = self.quant_method
        else:
            raise ValueError(
                f"The value {self.quant_method} is not supported. "
                f"Current supported methods: label-free, tmt"
            )

        self.json_data["proteomics_msgfplus.species"] = self.species
        self.json_data["proteomics_msgfplus.refine_prior"] = self.refine_prior
        self.json_data["proteomics_msgfplus.unique_only"] = self.unique_only
        self.json_data["proteomics_msgfplus.sequence_db_name"] = self.sequence_db_name
        # Extract proteomics experiment (pr/ph/ub/ac) from experiment_prot
        experiment_split = self.experiment_prot.split("-")
        proteomics_experiment = experiment_split[0]
        self.json_data[
            "proteomics_msgfplus.proteomics_experiment"
        ] = proteomics_experiment
        # print('self.proteomics_experiment = ', self.proteomics_experiment)
        return self.json_data


def main():
    # PROCESS ARGUMENTS
    opts = MSGFConfigurationGenerator()
    opts.sanitize_options()
    opts.argument_validation_output()
    opts.load_template()
    json_data = opts.fill_json()
    opts.save_configuration(json_data)

    print("+ ALL DONE!")


if __name__ == "__main__":
    dirname = os.path.dirname(__file__)
    print(dirname)
    main()
